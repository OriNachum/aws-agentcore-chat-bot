# Discord
DISCORD_BOT_TOKEN=your_discord_bot_token_here
DISCORD_CHANNEL_ID=123456789012345678

# Backend selection: agentcore or ollama
BACKEND_MODE=agentcore

# LLM Provider (when BACKEND_MODE=agentcore): ollama or bedrock
LLM_PROVIDER=bedrock

# Ollama local model settings (if LLM_PROVIDER=ollama)
OLLAMA_MODEL=llama3:8b
# OLLAMA_BASE_URL=http://localhost:11434

# AWS Bedrock settings (if LLM_PROVIDER=bedrock)
AWS_REGION=us-east-1
# Bedrock model ID - options include:
#   - us.amazon.nova-pro-v1:0 (Nova Pro - recommended)
#   - us.amazon.nova-lite-v1:0 (Nova Lite)
#   - us.amazon.nova-micro-v1:0 (Nova Micro)
#   - anthropic.claude-3-sonnet-20240229-v1:0 (Claude 3 Sonnet)
BEDROCK_MODEL_ID=us.amazon.nova-pro-v1:0
BEDROCK_TEMPERATURE=0.7
BEDROCK_MAX_TOKENS=4096
BEDROCK_STREAMING=true

# AWS AgentCore deployment settings (optional, for deployed agents)
AGENT_ID=your_agent_id
AGENT_ALIAS_ID=your_agent_alias_id

# AWS Bedrock Knowledge Base (optional)
# If you have a Bedrock KB, set these:
KNOWLEDGE_BASE_ID=your_kb_id
KNOWLEDGE_BASE_ENDPOINT=https://bedrock-agent-runtime.us-east-1.amazonaws.com/knowledgebases/YOUR_KB_ID/retrieve-and-generate

# Knowledge Base Direct Endpoint (required for KB integration)
# Should be the same as KNOWLEDGE_BASE_ENDPOINT
KB_DIRECT_ENDPOINT=https://bedrock-agent-runtime.us-east-1.amazonaws.com/knowledgebases/YOUR_KB_ID/retrieve-and-generate

AGENTCORE_MODE=false

# General
MAX_RESPONSE_CHARS=1800
LOG_LEVEL=INFO

# Prompt Management
# PROMPT_PROFILE=default
# PROMPT_ROOT=agents
# PROMPT_USER_ROLE=user
# SYSTEM_PROMPT=  # Inline override (bypasses profile file)

# Source Agents (automatic knowledge base updates)
SOURCE_AGENTS_ENABLED=false
# SOURCE_AGENTS_S3_BUCKET=my-kb-bucket
# SOURCE_AGENTS_S3_REGION=us-east-1
# SOURCE_AGENTS_DATA_SOURCE_ID=your-data-source-id
# SOURCE_AGENTS_RUN_ON_STARTUP=false
# SOURCE_AGENTS_INTERVAL=3600  # seconds
